# AndrewNG---ML---CS229
<h1>AndrewNG | Lecture Collection | Machine Learning | Standford CS229</h1>
<a href ='https://www.youtube.com/playlist?list=PLA89DCFA6ADACE599'><h3>Lecture Collection | Machine Learning | Standford</h3></a>
<a href ='http://cs229.stanford.edu/syllabus.html'><h3>Official Syllabus </h3></a>
1 An overview of the course in this introductory meeting.<br>
2 Linear Regression, gradient descent, and normal equations and discusses how they relate to machine learning. <br>
3 Locally weighted Regression, probabilistic interpretation and Logistic Regression and how it relates to machine learning. <br>
4 Newton's method, exponential families, and Generalized linear models and how they relate to machine learning. <br>
5 Generative learning algorithms and Gaussian discriminative analysis and their applications in machine learning. <br>
6 Naive Bayes, neural networks, and Support vector machine(SVM). <br>
7 Optimal margin classifiers, KKT conditions, and SUM duals. <br>
8 Support vector machines(SVM), including soft margin optimization and kernels. <br>
9 Learning theory, covering bias, variance, empirical risk minimization, union bound and Hoeffding's inequalities. <br>
10 Learning theory by discussing VC dimension and model selection. <br>
11 Bayesian statistics, regularization, digression-online learning, and the applications of machine learning algorithms. <br>
12 Unsupervised learning in the context of clustering, Jensen's inequality, mixture of Gaussians, and expectation-maximization. <br>
13 Expectation-maximization in the context of the mixture of Gaussian and naive Bayes models, as well as factor analysis and digression.<br>
14 Factor analysis and expectation-maximization steps, and continues on to discuss principal component analysis (PCA). <br>
15 Principal component analysis (PCA) and independent component analysis (ICA) in relation to unsupervised machine learning. <br>
16 Reinforcement learning, focusing particularly on MDPs, value functions, and policy and value iteration. <br>
17 Reinforcement learning, focusing particularly on continuous state MDPs, discretization, and policy and value iterations.<br>
18 State action rewards, linear dynamical systems in the context of linear quadratic regulation, models, and the Riccati equation, and finite horizon MDPs.<br>
19 Debugging process, linear quadratic regulation, Kalmer filters, and linear quadratic Gaussian in the context of reinforcement learning. <br>
20 POMDPs, policy search, and Pegasus in the context of reinforcement learning.ï»¿<br>
